{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath('__file__'))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\admin\\anaconda3\\envs\\torch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from utils.qwen.qw_chat_mode import chat_bot,make_context,operation_bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>system\\n<|im_end|>\\n<|im_start|>user\\nquery<|im_end|>\\n<|im_start|>assistant\\n'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "operation_bot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\admin\\anaconda3\\envs\\torch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers.generation import GenerationConfig\n",
    "# import \n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    r\"C:\\Users\\admin\\Desktop\\qw\\qwen\",\n",
    "    use_fast=False,\n",
    "    padding_side=\"left\",\n",
    "    trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['testb']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "re.findall('testb','test111atestb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\admin\\anaconda3\\envs\\torch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Warning: please make sure that you are using the latest codes and checkpoints, especially if you used Qwen-7B before 09.25.2023.请使用最新模型和代码，尤其如果你在9月25日前已经开始使用Qwen-7B，千万注意不要使用错误代码和模型。\n",
      "Warning: import flash_attn rotary fail, please install FlashAttention rotary to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/rotary\n",
      "Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm\n",
      "Warning: import flash_attn fail, please install FlashAttention to get higher efficiency https://github.com/Dao-AILab/flash-attention\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.93s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers.generation import GenerationConfig\n",
    "from utils.qwen.qw_chat_mode import chat_bot,make_context,operation_bot\n",
    "# Note: The default behavior now has injection attack prevention off.\n",
    "\n",
    "path = r\"C:\\Users\\admin\\Desktop\\新建文件夹\\glm_train\\merged_model\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(path, trust_remote_code=True)\n",
    "\n",
    "# use bf16\n",
    "model = AutoModelForCausalLM.from_pretrained(path, device_map=\"auto\", trust_remote_code=True, bf16=True).eval()\n",
    "\n",
    "from transformers import PreTrainedModel\n",
    "# from transformers_stream_generator.main import NewGenerationMixin, StreamGenerationConfig\n",
    "# generation_config = GenerationConfig.from_pretrained(path, trust_remote_code=True)\n",
    "# stream_config = StreamGenerationConfig(**generation_config.to_dict(), do_stream=True)\n",
    "# PreTrainedModel.generate = NewGenerationMixin.generate\n",
    "# PreTrainedModel.sample_stream = NewGenerationMixin.sample_stream\n",
    "from transformers import PreTrainedModel\n",
    "from transformers_stream_generator.main import NewGenerationMixin\n",
    "PreTrainedModel.generate = NewGenerationMixin.generate\n",
    "PreTrainedModel.sample_stream = NewGenerationMixin.sample_stream\n",
    "\n",
    "from transformers_stream_generator.main import StreamGenerationConfig\n",
    "\n",
    "\n",
    "\n",
    "generation_config = GenerationConfig.from_pretrained(path, trust_remote_code=True)\n",
    "generation_config = StreamGenerationConfig(**generation_config.to_dict(), do_stream=True)\n",
    "# chat_bot = operation_bot(model,tokenizer,None,None,None,generation_config=generation_config,sdmodel=None)\n",
    "ch_bot = chat_bot(model,tokenizer,generation_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operation.qw_prompt as prompt\n",
    "from utils.web_search import web_searcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前联网模式...\n",
      "[网页搜索] 每年苹果如约而至的新机总是让人期待不已，对于今年秋季上架的iPhone15系列机型，苹果肯定也是会调整四款机型的功能和定价的，在iPhone15和iPhone15Plus获得灵动岛功能之外，苹果将会在苹果将会为iPhone15Pro和iPhone15ProMax推出一些新的高端功能，以便于更好地区分。根据外媒MacRumors汇总的信息来看，iPhone15Pro和iPhone15ProMax可能会有以下六大独占功能：1.A17芯片根据NikkeiAsia报道，iPhone15Pro机型将配备基于台积电第二代3nm工艺制造的A17Bionic芯片，提升性能和效率。该报告称和去年相同，只有iPhone15Pro机型会配备苹果最新的芯片。2.钛金属框架据分析师JeffPu和泄密者“ShrimpApplePro”称，与AppleWatchUltra一样，iPhone15Pro机型的框架将改用钛金属，而不是不锈钢。3.采用USB-C端口据分析师郭明錤称，iPhone15Pro机型将配备至少支持USB3.2或Thunderbolt3的USB-C端口，这将使这些设备的数据传输速度显着加快。郭老师表示，标准iPhone15机型上的USB-C端口仍将限制为USB2.0速度。4.增加内存据研究公司TrendForce称，iPhone15Pro机型将配备增加的8GB内存，而标准机型可能会像目前一样继续配备6GB内存。额外的RAM可以让Safari等应用程序在后台保持更多内容处于活动状态，从而防止应用程序在重新打开时重新加载内容。5.固态按钮郭明錤说，iPhone15Pro机型将配备固态音量和电源按钮。分析师表示，这些设备将配备两个额外的TapticEngines，可提供触觉反馈来模拟按下按钮的感觉，而无需实际移动按钮，类似于最新款iPhoneSE上的Home按钮或新款MacBook上的触控板。6.光学变焦郭明錤表示iPhone15ProMax将配备潜望式长焦镜头。这可能让该设备至少具有6倍光学变焦，而iPhone14Pro机型为3倍。这六大功能你喜欢吗？\n",
      "一文读懂苹果新品发布会：iPhone15系列，到底升级了什么？作为科技春晚，苹果每年的iPhone新品发布会总能吸引到数码领域大部分人的目光。当然，目前有许多上班族无法熬夜，一觉醒来，当然需要一个最全面，最简洁的新品汇总。这场发布会的过程相较于以往要简短不少，只有4款新品。那么问题来了，这四款新品到底如何，能做到遥遥领先吗？第一款新品：AppleWatchS9根据苹果官方的介绍，AppleWatchS9内部重新设计，采用S9芯片，有56亿个晶体管，并且搭载了UWB芯片，可以用手表来找自己的手机，即便是手机处于静音状态，也能够轻松找到。与此同时，它还支持单手手势操作，通过佩戴手的大拇指和食指就能发出指令，无需另外一只手参与。其他配置，-屏幕峰值亮度高达2000nit，并且在性能更强的情况下，保持了18小时的续航时长。-一共8个配色，铝合金的粉金银黑红，不锈钢的金、银、石墨色，售价2999起,9月14日开售第二款新品：AppleWatchUltra2这款售价高达6499起的手表，采用了和AppleWatchS9一样的S9芯片以及UWB芯片，除了材质上的区别外，两者之间的区别主要在性能，Ultra2屏幕亮度高达3000nit，堪称遥遥领先。但是续航的成绩就比较一般了，常规情况下36小时，极限72小时，对比国产竞品还是有差距。第三款新品：iPhone15标准版/Plus作为本次发布会的两大硬菜之一，iPhone标准版升级到了A16芯片+第二代UWB芯片，可以和AppleWatchS9做到双向奔赴。另外最大的升级则是充电口换到了遥遥领先的「华为口」，并且支持反向充电，可以给AirPods供电。影像方面，采用4800万像素主摄，搭配1200万像素超广角，通过主摄规格的提升，达成类似2倍光变的效果。屏幕方面，加入灵动岛但没有高刷，峰值亮度2000nit。外观改用了弧形边框，一共有粉、绿、蓝、黄、黑五个配色.价格方面，标准版5999起，Plus6999起，入门配置依然是128G，9月15日开售。第四款新品：iPhone15Pro/ProMax作为每年的C位选手，Pro系列毫无疑问地官宣搭载了首款3nm芯片A17Pro，在能耗比方面有着很强的实力，是竞品的3倍。并且这颗芯片支持光线追踪的GPU，利好逆水寒和崩铁，甚至还能玩生化危机4。此外，它也同样采用了「华为口」设计，和标准版的区别是它支持USB3.0，在传输文件上，可以比USB2.0快20倍。另外一大升级点在于影像，采用全新抗眩光镜头，有望解决鬼影问题。规格配置上则是48MP主摄+12MP超广角+12MP5倍光变，这个长焦潜望镜头的结构比传统潜望更复杂，但只是ProMax的独占。Pro版依旧是3倍的变焦。外观方面，钛合金弧形边框显著减轻重量，并且加入了新的静音按钮，可以自定义功能：比如快速拍照、或者是语音备忘录，类似母公司的闪念胶囊。一共有四个配色：黑、银、蓝、灰。iPhone15Pro7999起，15ProMax则是9999起，入门配置也是128G，最高1T，9月15日开售。以上的这四款新品，升级幅度相对于以往的苹果来说，还是比较有诚意的。结合华为回归，并且提前开卖的大背景来看，苹果面临的压力不小。从功能卖点来看，iPhone15系列与Mate60系列之间也算是互有胜负，但毫无疑问的是，对比其他品牌，这两位都算是遥遥领先了。如果是你，你会怎么选？\n",
      "iPhone15还是14？如果看性价比那肯定选14，双十一马上就来，会有一波不小的降幅，但是大家喜新，那么分析一下：比起iPhone14，iPhone15全系升级点如下:全系标配「灵动岛」4800万像素镜头:基础款iPhone最高拍摄2400万像素尺寸，iPhone15Pro能够输出全像素的HEIF照片。第二代UWB超宽频USB-C:基础款iPhone仅支持USB2.0，而iPhone15Pro支持到USB3.2Gen2，10Gbps的速率。先说价格以：128g为例子，iPhone144999元，Phone15售价5999元起，相差1000元。。iPhone15升级亮点处理器方面:iPhone15标准版采用和iPhone14Pro相同的A16Bionic处理器，配有2个高性能核心和4个效率核心。iPhone15标准版配备OLEDSuperRetina显示屏，支持灵动岛，户外峰值亮度为2000尼特，支持1600尼特的DolbyVision。iPhone15标准版配备第二代UWB芯片，扩大了连接范围，可以在“查找我的”中进行精确查找。颜色方面:iPhone15标准版配有粉色，黄色，绿色，蓝色，黑色五种颜色。摄像头方面:iPhone15标准版配有4800万像素主摄，100%对焦像素，f1.6光圈，可以显示2倍无损裁剪缩放，配备1200万像素超广角摄像头，可以实现2倍变焦，拍摄4K视频。语音通话方面:iPhone15在嘈杂的通话环境中过滤你的声音，可选择“语音隔离”，自动切断背景噪音。怎么选看个人了，预测双十一iPhone14降价力度会更大！预算足的选Pro就行！点击:\n",
      "简单来说——数字版升级属于挤牙膏、Pro版是常规升级，都没有什么大的创新。iPhone15这机子，你要不怎么看重那个「灵动岛、USBType-C」，其实买降价的iPhone14可以省不少。或者花同样的钱买降价后的iPhone14Pro更合适。要不然iPhone15系列发布后，14Pro断货、涨价了呢，就是因为新款标准版挤牙膏？双击可看大图四款机型的具体配置都汇总在这张图表里了，下面咱们分别来看下iPhone15系列具体有哪些升级之处～关于iPhone15、15Plus：处理器升级为A16屏幕亮度大大提升，户外峰值亮度高达2000尼特，给了〔灵动岛〕但刷新率依旧是60Hz；接口换用USBType-C后置主摄提升至4800W像素第二代UWB芯片融色玻璃背板（哑光）颜色：粉、绿、黄、蓝、黑（这代机型配色比上一代漂亮）。其他：续航时间不变。iPhone15：128G5999元256G6999元512G8999元iPhone15Plus：128G6999元256G7999元512G9999元整体来看，基础版iPhone15、15Plus的提升没有啥太大的跨度，个人建议就是除非看重那个「灵动岛、USBType-C」，否则买降价的iPhone14更合适。iPhone15Pro、15ProMax的升级为与之前爆料的基本相符：处理器升级为A17Pro（3nm芯片、190亿晶体管、六核CPU速度提升10%，六核GPU峰值性能提升20%，16核神经引擎速度提升2倍。）钛合金中框，弧度加大，重量比上代机型均减少了19克；屏幕边框缩窄；Action按键代替了静音开关（长按Action键可以切换响铃和静音，也可以设置不同的功能切换如录音、启动相机等）；接口换用USBType-C（3.0）；后置主摄依旧是4800W像素但传感器面积增大，15ProMax独占5倍光学变焦（四重反射棱镜、传感器位移防抖）；支持4K60以及\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "result = ch_bot.mode3({'inputs':'What is new in iPhone 15'},history = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Apple'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Give a brief search prompt in Chinese according to the input and history.\\nHistory: {History}\\n\\nInput: {DESCRIPTION}\\nOutput:\"\n",
    "search_query = ch_bot.chat(prompt.format(DESCRIPTION='What is new in iPhone 15',History = None),ch_bot.generation_config,history=None)[0].strip().strip('\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'iPhone 15的新特性是什么？'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The iPhone 15 series will have six exclusive features for the Pro and Pro Max models, including:\n",
      "\n",
      "  1. A17 chip with a 3nm process and 190 billion transistors, which will improve performance and efficiency.\n",
      "  2. A titanium frame for the Pro and Pro Max models, replacing stainless steel.\n",
      "  3. Support for USB-C with at least 2.0 speeds, which will allow for faster data transfer.\n",
      "  4. Increased memory, with the Pro models getting 8GB of RAM and the standard models getting 6GB of RAM.\n",
      "  5. Optical zoom for the Pro Max model, with a 5x optical zoom and a 6x hybrid zoom.\n",
      "  6. Support for a subpixel optical touch sensor, which will provide haptic feedback for clicking and tapping the screen.\n",
      "\n",
      "The standard iPhone 15 models will not have these features.\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "import os\n",
    "import sys\n",
    "def _clear_screen():\n",
    "    os.system(\"cls\" if platform.system() == \"Windows\" else \"clear\")\n",
    "    if 'ipykernel' in sys.modules:\n",
    "        from IPython.display import clear_output as clear\n",
    "        clear()\n",
    "for res, history in result['chat']:\n",
    "    _clear_screen()\n",
    "    print(res,flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple is expected to release four new iPhones in 2023, including a high-end version that may be renamed \"iPhone Ultra.\" The new iPhones are expected to feature a new charging port, titanium frame, and faster charging speeds. The standard iPhone 15 model is expected to start at $599, while the high-end iPhone 15 Ultra is expected to start at $1,399. The new iPhones are also expected to have a larger screen size and a more advanced camera system.\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Answer the following questions as best you can. You have access to the following sources:\n",
    "\n",
    "Documents:    \n",
    "{documents}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "<|im_end|>\n",
      "<|im_start|>user\n",
      "华为Mate60pro怎么样<|im_end|>\n",
      "<|im_start|>assistant\n",
      "很好<|im_end|>\n",
      "<|im_start|>user\n",
      "它性能怎么样<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(make_context(tokenizer,query='它性能怎么样',history = [('华为Mate60pro怎么样','很好')])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(' 华为Mate60pro的性能如何？',\n",
       " [('Give a brief search prompt in Chinese according to the input and history.\\nHistory: User:华为Mate60pro怎么样\\nassistant:是一款新手机，非常好\\n\\nInput: 我想知道它的性能怎么样\\nOutput:',\n",
       "   ' 华为Mate60pro的性能如何？')])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = \"User:华为Mate60pro怎么样\\nassistant:是一款新手机，非常好\"\n",
    "query = \"Give a brief search prompt in Chinese according to the input and history.\\nHistory: {History}\\n\\nInput: {DESCRIPTION}\\nOutput:\"\n",
    "ch_bot.chat(query.format(DESCRIPTION='我想知道它的性能怎么样',History = history),generation_config,history=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "Please provide an answer in the required format based on the known information.\n",
      "\n",
      "Infomation:电脑当前屏幕亮度为50%\n",
      "\n",
      "Input:如果用户需要“帮我调低亮度”，模仿“现在电脑当前亮度为X%，已调至Y%”的样式进行回答。<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt.Prompt0('帮我调低亮度','电脑当前屏幕亮度为50%').prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"<|im_start|>system\n",
    "You are a helpful assistant.<|im_end|>\n",
    "<|im_start|>user\n",
    "Please provide an correct answer in the required format based on the known information.\n",
    "\n",
    "Infomation:电脑当前亮度为50%\n",
    "\n",
    "Input:如果用户需要“帮我调低亮度到1%”，模仿“现在电脑当前亮度为X%，已调至Y%”的样式进行回答<|im_end|>\n",
    "<|im_start|>assistant\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\nPlease provide an answer in the required format based on the known information.\\n\\nInfomation:电脑当前屏幕亮度为50%\\n\\nInput:如果用户需要“帮我调低亮度”，模仿“您现在电脑当前亮度为X%，已调至Y%”进行回答<|im_end|>\\n<|im_start|>assistant\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.Prompt0('帮我调低亮度','电脑当前屏幕亮度为50%').prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[数字提取]  好的，现在电脑当前亮度为50%，已调至40%。\n"
     ]
    }
   ],
   "source": [
    "chat_bot._extract_info(prompt.Prompt0('帮我调低亮度','电脑当前屏幕亮度为50%').prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    }
   ],
   "source": [
    "tokenizer.pad_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QWenLMHeadModel(\n",
       "  (transformer): QWenModel(\n",
       "    (wte): Embedding(151936, 4096)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (rotary_emb): RotaryEmbedding()\n",
       "    (h): ModuleList(\n",
       "      (0-31): 32 x QWenBlock(\n",
       "        (ln_1): RMSNorm()\n",
       "        (attn): QWenAttention(\n",
       "          (c_attn): Linear(in_features=4096, out_features=12288, bias=True)\n",
       "          (c_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (core_attention_flash): FlashSelfAttention()\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln_2): RMSNorm()\n",
       "        (mlp): QWenMLP(\n",
       "          (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (w2): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (c_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): RMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T_destination',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_auto_class',\n",
       " '_backward_compatibility_gradient_checkpointing',\n",
       " '_backward_hooks',\n",
       " '_backward_pre_hooks',\n",
       " '_buffers',\n",
       " '_call_impl',\n",
       " '_convert_head_mask_to_5d',\n",
       " '_create_repo',\n",
       " '_expand_inputs_for_generation',\n",
       " '_extract_past_from_model_output',\n",
       " '_forward_hooks',\n",
       " '_forward_hooks_with_kwargs',\n",
       " '_forward_pre_hooks',\n",
       " '_forward_pre_hooks_with_kwargs',\n",
       " '_from_config',\n",
       " '_get_backward_hooks',\n",
       " '_get_backward_pre_hooks',\n",
       " '_get_decoder_start_token_id',\n",
       " '_get_files_timestamps',\n",
       " '_get_generation_mode',\n",
       " '_get_logits_processor',\n",
       " '_get_logits_warper',\n",
       " '_get_name',\n",
       " '_get_resized_embeddings',\n",
       " '_get_resized_lm_head',\n",
       " '_get_stopping_criteria',\n",
       " '_hook_rss_memory_post_forward',\n",
       " '_hook_rss_memory_pre_forward',\n",
       " '_init_weights',\n",
       " '_initialize_weights',\n",
       " '_is_full_backward_hook',\n",
       " '_is_hf_initialized',\n",
       " '_keep_in_fp32_modules',\n",
       " '_keys_to_ignore_on_load_missing',\n",
       " '_keys_to_ignore_on_load_unexpected',\n",
       " '_keys_to_ignore_on_save',\n",
       " '_load_from_state_dict',\n",
       " '_load_pretrained_model',\n",
       " '_load_pretrained_model_low_mem',\n",
       " '_load_state_dict_post_hooks',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_maybe_initialize_input_ids_for_generation',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_merge_criteria_processor_list',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_no_split_modules',\n",
       " '_non_persistent_buffers_set',\n",
       " '_parameters',\n",
       " '_prepare_attention_mask_for_generation',\n",
       " '_prepare_decoder_input_ids_for_generation',\n",
       " '_prepare_encoder_decoder_kwargs_for_generation',\n",
       " '_prepare_model_inputs',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_reorder_cache',\n",
       " '_replicate_for_data_parallel',\n",
       " '_resize_token_embeddings',\n",
       " '_save_to_state_dict',\n",
       " '_set_default_torch_dtype',\n",
       " '_set_gradient_checkpointing',\n",
       " '_skip_keys_device_placement',\n",
       " '_slow_forward',\n",
       " '_state_dict_hooks',\n",
       " '_state_dict_pre_hooks',\n",
       " '_tie_encoder_decoder_weights',\n",
       " '_tie_or_clone_weights',\n",
       " '_tied_weights_keys',\n",
       " '_update_model_kwargs_for_generation',\n",
       " '_upload_modified_files',\n",
       " '_validate_generated_length',\n",
       " '_validate_model_class',\n",
       " '_validate_model_kwargs',\n",
       " '_version',\n",
       " 'add_memory_hooks',\n",
       " 'add_module',\n",
       " 'apply',\n",
       " 'assisted_decoding',\n",
       " 'base_model',\n",
       " 'base_model_prefix',\n",
       " 'beam_sample',\n",
       " 'beam_search',\n",
       " 'bfloat16',\n",
       " 'buffers',\n",
       " 'call_super_init',\n",
       " 'can_generate',\n",
       " 'chat',\n",
       " 'chat_stream',\n",
       " 'children',\n",
       " 'compute_transition_scores',\n",
       " 'config',\n",
       " 'config_class',\n",
       " 'constrained_beam_search',\n",
       " 'contrastive_search',\n",
       " 'cpu',\n",
       " 'create_extended_attention_mask_for_decoder',\n",
       " 'cuda',\n",
       " 'device',\n",
       " 'disable_input_require_grads',\n",
       " 'double',\n",
       " 'dtype',\n",
       " 'dummy_inputs',\n",
       " 'dump_patches',\n",
       " 'enable_input_require_grads',\n",
       " 'estimate_tokens',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'float',\n",
       " 'floating_point_ops',\n",
       " 'forward',\n",
       " 'framework',\n",
       " 'from_pretrained',\n",
       " 'generate',\n",
       " 'generation_config',\n",
       " 'get_buffer',\n",
       " 'get_extended_attention_mask',\n",
       " 'get_extra_state',\n",
       " 'get_head_mask',\n",
       " 'get_input_embeddings',\n",
       " 'get_memory_footprint',\n",
       " 'get_output_embeddings',\n",
       " 'get_parameter',\n",
       " 'get_position_embeddings',\n",
       " 'get_submodule',\n",
       " 'gradient_checkpointing_disable',\n",
       " 'gradient_checkpointing_enable',\n",
       " 'greedy_search',\n",
       " 'group_beam_search',\n",
       " 'half',\n",
       " 'hf_device_map',\n",
       " 'init_weights',\n",
       " 'invert_attention_mask',\n",
       " 'ipu',\n",
       " 'is_gradient_checkpointing',\n",
       " 'is_loaded_in_4bit',\n",
       " 'is_loaded_in_8bit',\n",
       " 'is_parallelizable',\n",
       " 'lm_head',\n",
       " 'load_state_dict',\n",
       " 'main_input_name',\n",
       " 'modules',\n",
       " 'name_or_path',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'num_parameters',\n",
       " 'parameters',\n",
       " 'post_init',\n",
       " 'prepare_inputs_for_generation',\n",
       " 'prune_heads',\n",
       " 'push_to_hub',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_for_auto_class',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_full_backward_pre_hook',\n",
       " 'register_load_state_dict_post_hook',\n",
       " 'register_module',\n",
       " 'register_parameter',\n",
       " 'register_state_dict_pre_hook',\n",
       " 'requires_grad_',\n",
       " 'reset_memory_hooks_state',\n",
       " 'resize_position_embeddings',\n",
       " 'resize_token_embeddings',\n",
       " 'retrieve_modules_from_names',\n",
       " 'reverse_bettertransformer',\n",
       " 'sample',\n",
       " 'save_pretrained',\n",
       " 'set_extra_state',\n",
       " 'set_input_embeddings',\n",
       " 'set_output_embeddings',\n",
       " 'share_memory',\n",
       " 'state_dict',\n",
       " 'supports_gradient_checkpointing',\n",
       " 'tie_weights',\n",
       " 'to',\n",
       " 'to_bettertransformer',\n",
       " 'to_empty',\n",
       " 'train',\n",
       " 'training',\n",
       " 'transformer',\n",
       " 'type',\n",
       " 'warn_if_padding_and_no_attention_mask',\n",
       " 'warnings_issued',\n",
       " 'xpu',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QWenLMHeadModel(\n",
       "  (transformer): QWenModel(\n",
       "    (wte): Embedding(151936, 4096)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (rotary_emb): RotaryEmbedding()\n",
       "    (h): ModuleList(\n",
       "      (0-31): 32 x QWenBlock(\n",
       "        (ln_1): RMSNorm()\n",
       "        (attn): QWenAttention(\n",
       "          (c_attn): Linear(in_features=4096, out_features=12288, bias=True)\n",
       "          (c_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln_2): RMSNorm()\n",
       "        (mlp): QWenMLP(\n",
       "          (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (w2): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (c_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): RMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QWenLMHeadModel(\n",
       "  (transformer): QWenModel(\n",
       "    (wte): Embedding(151936, 4096)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (rotary_emb): RotaryEmbedding()\n",
       "    (h): ModuleList(\n",
       "      (0-31): 32 x QWenBlock(\n",
       "        (ln_1): RMSNorm()\n",
       "        (attn): QWenAttention(\n",
       "          (c_attn): Linear(in_features=4096, out_features=12288, bias=True)\n",
       "          (c_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln_2): RMSNorm()\n",
       "        (mlp): QWenMLP(\n",
       "          (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (w2): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (c_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): RMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.get_submodule of QWenLMHeadModel(\n",
       "  (transformer): QWenModel(\n",
       "    (wte): Embedding(151936, 4096)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (rotary_emb): RotaryEmbedding()\n",
       "    (h): ModuleList(\n",
       "      (0-31): 32 x QWenBlock(\n",
       "        (ln_1): RMSNorm()\n",
       "        (attn): QWenAttention(\n",
       "          (c_attn): Linear(in_features=4096, out_features=12288, bias=True)\n",
       "          (c_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln_2): RMSNorm()\n",
       "        (mlp): QWenMLP(\n",
       "          (w1): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (w2): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (c_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): RMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=151936, bias=False)\n",
       ")>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_submodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'QWenLMHeadModel' object has no attribute 'layer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\admin\\LenoMate\\test.ipynb 单元格 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/admin/LenoMate/test.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mlayer\n",
      "File \u001b[1;32md:\\Users\\admin\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1612\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[0;32m   1613\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1614\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   1615\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'QWenLMHeadModel' object has no attribute 'layer'"
     ]
    }
   ],
   "source": [
    "model.layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query,history = chat_bot.chat('帮我介绍一下深圳，列出深圳的五个优势',generation_config=generation_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('深圳是中国改革开放的前沿城市，经济发展迅速，是中国南方重要的经济中心之一。深圳是中国最早实行市场经济改革的城市之一，吸引了大量国内外投资者和企业家。深圳的经济以制造业为主，拥有众多高科技企业，是中国科技创新的领导者之一。深圳的港口也是中国南方重要的港口之一，为深圳的经济发展提供了重要的支持。',\n",
       " [('帮我介绍一下深圳，列出深圳的五个优势',\n",
       "   '深圳是中国南部沿海城市，拥有丰富的历史文化和现代化的城市建设。以下是深圳的五个优势：\\n\\n1. 经济发展：深圳是中国改革开放的前沿城市，经济实力强大，是中国南方重要的经济中心之一。\\n\\n2. 技术创新：深圳是中国科技创新的热点地区，拥有众多高科技企业，是中国科技创新的领导者之一。\\n\\n3. 人才聚集：深圳吸引了大量国内外优秀人才，拥有高水平的人才储备和人力资源。\\n\\n4. 城市环境：深圳的城市环境优美，拥有众多公园和自然景观，是一个宜居的城市。\\n\\n5. 文化多元：深圳是一个文化多元的城市，拥有丰富的文化资源和多元化的文化氛围。'),\n",
       "  ('详细介绍一下第一点',\n",
       "   '深圳是中国改革开放的前沿城市，经济发展迅速，是中国南方重要的经济中心之一。深圳是中国最早实行市场经济改革的城市之一，吸引了大量国内外投资者和企业家。深圳的经济以制造业为主，拥有众多高科技企业，是中国科技创新的领导者之一。深圳的港口也是中国南方重要的港口之一，为深圳的经济发展提供了重要的支持。')])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_bot.chat('详细介绍一下第一点',generation_config=generation_config,history=history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'抱歉，作为一款AI语言模型，我无法获取实时天气信息。你可以通过查询天气网站或使用手机上的天气应用程序来获取最新的天气预报。'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('深圳是中国南部沿海城市，拥有丰富的历史文化和现代化的城市建设。以下是深圳的五个优势：\\n\\n1. 经济发展：深圳是中国改革开放的前沿城市，经济实力强大，是中国南方重要的经济中心之一。\\n\\n2. 技术创新：深圳是中国科技创新的热点地区，拥有众多高科技企业，是中国科技创新的领导者之一。\\n\\n3. 人才聚集：深圳吸引了大量国内外优秀人才，拥有高水平的人才储备和人力资源。\\n\\n4. 城市环境：深圳的城市环境优美，拥有众多公园和自然景观，是一个宜居的城市。\\n\\n5. 文化多元：深圳是一个文化多元的城市，拥有丰富的文化资源和多元化的文化氛围。',\n",
       " [('帮我介绍一下深圳，列出深圳的五个优势',\n",
       "   '深圳是中国南部沿海城市，拥有丰富的历史文化和现代化的城市建设。以下是深圳的五个优势：\\n\\n1. 经济发展：深圳是中国改革开放的前沿城市，经济实力强大，是中国南方重要的经济中心之一。\\n\\n2. 技术创新：深圳是中国科技创新的热点地区，拥有众多高科技企业，是中国科技创新的领导者之一。\\n\\n3. 人才聚集：深圳吸引了大量国内外优秀人才，拥有高水平的人才储备和人力资源。\\n\\n4. 城市环境：深圳的城市环境优美，拥有众多公园和自然景观，是一个宜居的城市。\\n\\n5. 文化多元：深圳是一个文化多元的城市，拥有丰富的文化资源和多元化的文化氛围。')])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query,history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system\n",
      "You are a helpful assistant named LenoMate from Lenovo.\n",
      "user\n",
      "今天天气怎么样\n",
      "assistant\n",
      "我无法获取实时天气信息，但你可以通过查询天气预报或使用天气应用程序来获取最新的天气信息。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(history[0][1][0],skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([151644,   8948,    198,   2610,    525,    264,  10950,  17847,   6941,\n",
       "           444,  11790,  96642,    504,  63699,     13, 151645,    198, 151644,\n",
       "           872,    198, 100644, 104307, 104472, 151645,    198, 151644,  77091,\n",
       "           198,  35946, 101068,  45912, 105143, 104307,  27369,   3837,  77288,\n",
       "        105048,  67338,  51154, 104307, 115744,  57191,  37029, 104307, 113384,\n",
       "         36407,  45912, 108324, 104307,  27369,   1773, 151645,    198, 151644,\n",
       "        151643], device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history[0][1][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
